#!/usr/bin/env python3
"""
Copilotå¿œç­”æ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å®Ÿéš›ã®Copilotå¿œç­”ã‚’å–å¾—ãƒ»æ¤œè¨¼ã—ã€
å½é™½æ€§ã‚’æ’é™¤ã™ã‚‹ãŸã‚å®Ÿéš›ã®å¿œç­”å†…å®¹ã‚’å³å¯†ã«ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
"""

import json
import time
import hashlib
import logging
from typing import Dict, Any, Optional, Tuple, List
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CopilotResponse:
    """Copilotå¿œç­”ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    success: bool
    instruction_id: str
    actual_response: str
    model: str
    execution_time: float
    timestamp: str
    verification_hash: str
    response_length: int
    is_mock: bool = False
    error_message: Optional[str] = None

class CopilotVerifier:
    """Copilotå¿œç­”æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, workspace_path: str = "/home/jinno/copilot-instruction-eval"):
        self.workspace_path = workspace_path
        self.extension_dir = Path(workspace_path) / ".vscode" / "copilot-automation"
        self.result_file = self.extension_dir / "execution_result.json"
        
        # æ—¢çŸ¥ã®ãƒ¢ãƒƒã‚¯å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.mock_patterns = [
            "This is a mock response",
            "mock response from Copilot",
            "test response",
            "placeholder response",
            "dummy response"
        ]
        
        # æœ€å°å¿œç­”é•·ï¼ˆå®Ÿéš›ã®å¿œç­”ã¨åˆ¤æ–­ã™ã‚‹åŸºæº–ï¼‰
        self.min_real_response_length = 20
        
    def _calculate_verification_hash(self, response_data: Dict[str, Any]) -> str:
        """å¿œç­”ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        # ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ç”¨ã®æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿
        normalized_data = {
            "response": response_data.get("response", ""),
            "timestamp": response_data.get("timestamp", ""),
            "model": response_data.get("model", ""),
            "instruction_id": response_data.get("instruction_id", "")
        }
        
        data_str = json.dumps(normalized_data, sort_keys=True)
        return hashlib.sha256(data_str.encode()).hexdigest()
    
    def _is_mock_response(self, response_text: str) -> bool:
        """ãƒ¢ãƒƒã‚¯å¿œç­”ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if not response_text:
            return True
        
        response_lower = response_text.lower()
        
        # æ—¢çŸ¥ã®ãƒ¢ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern in self.mock_patterns:
            if pattern.lower() in response_lower:
                logger.warning(f"ğŸ­ Mock pattern detected: {pattern}")
                return True
        
        # å¿œç­”é•·ãƒã‚§ãƒƒã‚¯
        if len(response_text) < self.min_real_response_length:
            logger.warning(f"ğŸ“ Response too short ({len(response_text)} chars)")
            return True
        
        # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        words = response_text.split()
        if len(set(words)) < len(words) * 0.3:  # 30%æœªæº€ãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå˜èª
            logger.warning("ğŸ”„ Repetitive response pattern detected")
            return True
        
        return False
    
    def _validate_response_structure(self, response_data: Dict[str, Any]) -> Tuple[bool, str]:
        """å¿œç­”ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼"""
        required_fields = ["success", "response", "timestamp", "model"]
        
        for field in required_fields:
            if field not in response_data:
                return False, f"Missing required field: {field}"
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œè¨¼
        try:
            timestamp = response_data["timestamp"]
            if isinstance(timestamp, (int, float)):
                # Unix timestamp
                response_time = datetime.fromtimestamp(timestamp)
            else:
                # ISO format
                response_time = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            
            # å¿œç­”ãŒæ–°ã—ã„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆéå»1æ™‚é–“ä»¥å†…ï¼‰
            time_diff = datetime.now() - response_time.replace(tzinfo=None)
            if time_diff.total_seconds() > 3600:  # 1æ™‚é–“
                return False, f"Response too old: {time_diff}"
                
        except Exception as e:
            return False, f"Invalid timestamp format: {e}"
        
        return True, "Valid structure"
    
    def _analyze_response_quality(self, response_text: str, instruction: str = "") -> Dict[str, Any]:
        """å¿œç­”å“è³ªã®åˆ†æ"""
        analysis = {
            "length": len(response_text),
            "word_count": len(response_text.split()),
            "has_code": "```" in response_text or "def " in response_text or "function " in response_text,
            "has_explanation": len(response_text.split('.')) > 2,
            "relevance_score": 0.0
        }
        
        # é–¢é€£æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if instruction:
            instruction_words = set(instruction.lower().split())
            response_words = set(response_text.lower().split())
            common_words = instruction_words.intersection(response_words)
            if instruction_words:
                analysis["relevance_score"] = len(common_words) / len(instruction_words)
        
        return analysis
    
    def verify_copilot_response(self, instruction_id: str, instruction_text: str = "", timeout: int = 60) -> CopilotResponse:
        """Copilotå¿œç­”ã‚’æ¤œè¨¼"""
        logger.info(f"ğŸ” Verifying Copilot response for: {instruction_id}")
        
        start_time = time.time()
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«å¾…æ©Ÿ
        wait_start = time.time()
        while time.time() - wait_start < timeout:
            if self.result_file.exists():
                try:
                    with open(self.result_file, 'r', encoding='utf-8') as f:
                        response_data = json.load(f)
                    
                    # æŒ‡ç¤ºIDãƒãƒƒãƒãƒ³ã‚°ç¢ºèª
                    if response_data.get("instruction_id") == instruction_id:
                        break
                    
                except Exception as e:
                    logger.debug(f"âš ï¸ Error reading result file: {e}")
            
            time.sleep(1)
        else:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            logger.error(f"âŒ Response timeout for {instruction_id}")
            return CopilotResponse(
                success=False,
                instruction_id=instruction_id,
                actual_response="",
                model="unknown",
                execution_time=time.time() - start_time,
                timestamp=datetime.now().isoformat(),
                verification_hash="",
                response_length=0,
                error_message="Response timeout"
            )
        
        # å¿œç­”ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        try:
            execution_time = time.time() - start_time
            
            # æ§‹é€ æ¤œè¨¼
            is_valid, validation_message = self._validate_response_structure(response_data)
            if not is_valid:
                logger.error(f"âŒ Invalid response structure: {validation_message}")
                return CopilotResponse(
                    success=False,
                    instruction_id=instruction_id,
                    actual_response="",
                    model="unknown",
                    execution_time=execution_time,
                    timestamp=datetime.now().isoformat(),
                    verification_hash="",
                    response_length=0,
                    error_message=f"Invalid structure: {validation_message}"
                )
            
            # å¿œç­”å†…å®¹å–å¾—
            response_text = response_data.get("response", "")
            model = response_data.get("model", "unknown")
            timestamp = response_data.get("timestamp", datetime.now().isoformat())
            
            # ãƒ¢ãƒƒã‚¯å¿œç­”ãƒã‚§ãƒƒã‚¯
            is_mock = self._is_mock_response(response_text)
            if is_mock:
                logger.warning(f"ğŸ­ Mock response detected for {instruction_id}")
            
            # æ¤œè¨¼ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
            verification_hash = self._calculate_verification_hash(response_data)
            
            # å¿œç­”å“è³ªåˆ†æ
            quality_analysis = self._analyze_response_quality(response_text, instruction_text)
            
            # æˆåŠŸåˆ¤å®š
            success = (
                response_data.get("success", False) and
                not is_mock and
                len(response_text) >= self.min_real_response_length and
                quality_analysis["relevance_score"] > 0.1
            )
            
            logger.info(f"{'âœ…' if success else 'âŒ'} Response verification: {instruction_id}")
            logger.info(f"ğŸ“Š Quality: Length={quality_analysis['length']}, Relevance={quality_analysis['relevance_score']:.2f}, Mock={is_mock}")
            
            return CopilotResponse(
                success=success,
                instruction_id=instruction_id,
                actual_response=response_text,
                model=model,
                execution_time=execution_time,
                timestamp=str(timestamp),
                verification_hash=verification_hash,
                response_length=len(response_text),
                is_mock=is_mock,
                error_message=None if success else "Response quality insufficient"
            )
            
        except Exception as e:
            logger.error(f"âŒ Response verification error: {e}")
            return CopilotResponse(
                success=False,
                instruction_id=instruction_id,
                actual_response="",
                model="unknown",
                execution_time=time.time() - start_time,
                timestamp=datetime.now().isoformat(),
                verification_hash="",
                response_length=0,
                error_message=f"Verification error: {e}"
            )
    
    def batch_verify_responses(self, instruction_ids: List[str], timeout_per_response: int = 60) -> List[CopilotResponse]:
        """è¤‡æ•°ã®å¿œç­”ã‚’ä¸€æ‹¬æ¤œè¨¼"""
        logger.info(f"ğŸ” Batch verifying {len(instruction_ids)} responses...")
        
        results = []
        for instruction_id in instruction_ids:
            response = self.verify_copilot_response(instruction_id, timeout=timeout_per_response)
            results.append(response)
            
            # é€²æ—ãƒ­ã‚°
            success_count = sum(1 for r in results if r.success)
            logger.info(f"ğŸ“Š Progress: {len(results)}/{len(instruction_ids)} ({success_count} successful)")
        
        return results
    
    def get_verification_summary(self, responses: List[CopilotResponse]) -> Dict[str, Any]:
        """æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        if not responses:
            return {"total": 0, "successful": 0, "success_rate": 0.0}
        
        successful = [r for r in responses if r.success]
        mock_responses = [r for r in responses if r.is_mock]
        
        total_length = sum(r.response_length for r in successful)
        avg_length = total_length / len(successful) if successful else 0
        
        avg_execution_time = sum(r.execution_time for r in responses) / len(responses)
        
        summary = {
            "total": len(responses),
            "successful": len(successful),
            "failed": len(responses) - len(successful),
            "mock_detected": len(mock_responses),
            "success_rate": len(successful) / len(responses) * 100,
            "average_response_length": avg_length,
            "average_execution_time": avg_execution_time,
            "verification_timestamp": datetime.now().isoformat()
        }
        
        return summary

def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    verifier = CopilotVerifier()
    
    print("=== Copilot Verifier Test ===")
    
    # å˜ä¸€å¿œç­”æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # response = verifier.verify_copilot_response("test_001")
    # print(f"Verification result: {response}")

if __name__ == "__main__":
    main()
