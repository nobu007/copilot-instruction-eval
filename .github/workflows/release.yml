name: Release and Deployment

on:
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      version:
        description: 'Release version'
        required: true
        default: 'v1.0.0'

env:
  PYTHON_VERSION: '3.11'

jobs:
  validate-release:
    name: Validate Release
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest
    
    - name: Run comprehensive tests
      run: |
        pytest tests/ -v --tb=short
    
    - name: Validate evaluation system
      run: |
        python evaluate_agents.py --demo-mode
        test -f results/evaluation_results.json
        test -f results/evaluation_report.md
    
    - name: Check documentation
      run: |
        test -f README.md
        test -f docs/TASKS.md
        test -f requirements.txt

  build-package:
    name: Build Distribution Package
    runs-on: ubuntu-latest
    needs: validate-release
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Create package metadata
      run: |
        cat > setup.py << EOF
        from setuptools import setup, find_packages
        
        setup(
            name="copilot-instruction-eval",
            version="${{ github.event.inputs.version || github.ref_name }}",
            description="GitHub Copilot Instruction Evaluation System",
            long_description=open("README.md").read(),
            long_description_content_type="text/markdown",
            author="Copilot Evaluation Team",
            packages=find_packages(),
            install_requires=open("requirements.txt").read().splitlines(),
            python_requires=">=3.9",
            entry_points={
                "console_scripts": [
                    "copilot-eval=evaluate_agents:main",
                ],
            },
            classifiers=[
                "Development Status :: 4 - Beta",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.9",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.12",
            ],
        )
        EOF
    
    - name: Build package
      run: |
        python -m build
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: distribution-packages
        path: dist/
        retention-days: 90

  create-release-notes:
    name: Create Release Notes
    runs-on: ubuntu-latest
    needs: build-package
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Generate release notes
      run: |
        echo "# Release Notes for ${{ github.event.inputs.version || github.ref_name }}" > release-notes.md
        echo "" >> release-notes.md
        echo "## ðŸŽ¯ Features" >> release-notes.md
        echo "- âœ… Comprehensive Copilot instruction evaluation system" >> release-notes.md
        echo "- âœ… Automated recording and analysis of user interactions" >> release-notes.md
        echo "- âœ… Multi-agent comparison with detailed metrics" >> release-notes.md
        echo "- âœ… Interactive GUI for test harness and evaluation" >> release-notes.md
        echo "- âœ… Comprehensive test suite with CI/CD integration" >> release-notes.md
        echo "" >> release-notes.md
        echo "## ðŸ“Š Evaluation Metrics" >> release-notes.md
        echo "- Jaccard similarity analysis" >> release-notes.md
        echo "- BLEU score computation" >> release-notes.md
        echo "- ROUGE-1, ROUGE-2, ROUGE-L metrics" >> release-notes.md
        echo "- Response time measurement" >> release-notes.md
        echo "- Success rate tracking" >> release-notes.md
        echo "" >> release-notes.md
        echo "## ðŸ”§ Technical Improvements" >> release-notes.md
        echo "- Demo mode for testing without API dependencies" >> release-notes.md
        echo "- Robust error handling and retry mechanisms" >> release-notes.md
        echo "- Comprehensive logging and debugging support" >> release-notes.md
        echo "- Multi-platform compatibility (Python 3.9+)" >> release-notes.md
        echo "" >> release-notes.md
        echo "## ðŸ“¦ Installation" >> release-notes.md
        echo "\`\`\`bash" >> release-notes.md
        echo "pip install copilot-instruction-eval" >> release-notes.md
        echo "\`\`\`" >> release-notes.md
        echo "" >> release-notes.md
        echo "## ðŸš€ Quick Start" >> release-notes.md
        echo "\`\`\`bash" >> release-notes.md
        echo "# Run evaluation in demo mode" >> release-notes.md
        echo "copilot-eval --demo-mode" >> release-notes.md
        echo "" >> release-notes.md
        echo "# Run with custom instructions" >> release-notes.md
        echo "copilot-eval --instructions custom_instructions.json" >> release-notes.md
        echo "\`\`\`" >> release-notes.md
    
    - name: Upload release notes
      uses: actions/upload-artifact@v3
      with:
        name: release-notes
        path: release-notes.md
        retention-days: 90

  deploy-docs:
    name: Deploy Documentation
    runs-on: ubuntu-latest
    needs: validate-release
    if: github.event_name == 'release'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Generate documentation
      run: |
        mkdir -p docs-site
        cp README.md docs-site/
        cp docs/TASKS.md docs-site/
        
        # Generate API documentation if needed
        pip install pdoc3
        pdoc3 --html --output-dir docs-site evaluate_agents
    
    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./docs-site
        publish_branch: gh-pages
        commit_message: 'Deploy documentation for ${{ github.ref_name }}'